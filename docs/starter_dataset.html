---

title: Starter Dataset


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/01_starter_dataset.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_starter_dataset.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Download/Installation">Download/Installation<a class="anchor-link" href="#Download/Installation"> </a></h2><p><strong><code>omnitools.download</code> is a one-line utility for downloading the starter (and other similar) datasets.</strong></p>
<p>The download tool is designed to be fast and easy to use (it's built off of <a href="https://aria2.github.io/">aria2</a>). We regularly get 70MB/s downloading from the EPFL servers to Berkeley. It's written pretty generally, too, so the tool can also be used to download other datasets stored in a similar format (i.e. other datasets formatted similarly to annotator outputs, like <a href="//taskonomy.stanford.edu">Taskonomy</a>).
<br><strong><em>Note:</em></strong> There's also an inverse <strong><code>omnitools.upload</code></strong> for uploading an annotator-generated dataset to a server.
<!-- **_NOTE:_  There's also a complementary `omnitools.upload` that compresses and stores datasets in a compliant format. If you use the omnidata annotator to create a new datset, then `omnitools.upload` might be useful for when you want to distribute that dataset. I.e. other people will be able to use the download tool to download your dataset.** --></p>
<p>To download the starter dataset, make sure that omnidata-tooling is installed (<code>pip install omnidata-tools</code>) and then run the full download command which will prompt you to accept the component licenses and then proceed:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="c1"># Install a the &#39;debug&#39; subsets of the Replica and Taskonomy components of the dataset</span>
omnitools.download rgb normals point_info <span class="se">\</span>
  --components replica taskonomy <span class="se">\</span>
  --subset debug <span class="se">\</span>
  --dest ./omnidata_starter_dataset/ <span class="se">\</span>
  --connections_total <span class="m">30</span> --agree
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://alexsax.github.io/omnidata-tools/images/download_example.jpg" alt="./assets/download_example.jpg"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Command-line-options">Command-line options<a class="anchor-link" href="#Command-line-options"> </a></h3><p><code>omnitools.download</code> is pretty configurable, and you can choose which comonents/subset/split/tasks to download and extract. The downloader will spawn many workers to then download those compressed files, verify the download against checksums on the server, and unpack them. Here are the available options:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">anno_parser</span><span class="p">(</span><span class="n">download</span><span class="p">)</span><span class="o">.</span><span class="n">print_help</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>usage: ipykernel_launcher.py [-h] [--subset {debug,tiny,medium,full,fullplus}]
                             [--split {train,val,test,all}]
                             [--components {all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} [{all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} ...]]
                             [--dest DEST] [--dest_compressed DEST_COMPRESSED]
                             [--keep_compressed KEEP_COMPRESSED] [--only_download ONLY_DOWNLOAD]
                             [--max_tries_per_model MAX_TRIES_PER_MODEL]
                             [--connections_total CONNECTIONS_TOTAL]
                             [--connections_per_server_per_download CONNECTIONS_PER_SERVER_PER_DOWNLOAD]
                             [--n_workers N_WORKERS] [--num_chunk NUM_CHUNK]
                             [--num_total_chunks NUM_TOTAL_CHUNKS]
                             [--ignore_checksum IGNORE_CHECKSUM] [--dryrun] [--aria2_uri ARIA2_URI]
                             [--aria2_cmdline_opts ARIA2_CMDLINE_OPTS]
                             [--aria2_create_server ARIA2_CREATE_SERVER]
                             [--aria2_secret ARIA2_SECRET] [--agree_all]
                             domains [domains ...]

Downloads Omnidata starter dataset. --- The data is stored on the remote server in a compressed
format (.tar.gz). This function downloads the compressed and decompresses it. Examples: python
download_tools.py rgb normals point_info --components clevr_simple clevr_complex --connections_total
30

positional arguments:
  domains                                         Domains to download (comma-separated or &#39;all&#39;)

optional arguments:
  -h, --help                                      show this help message and exit
  --subset {debug,tiny,medium,full,fullplus}      Subset to download (default: debug)
  --split {train,val,test,all}                    Split to download (default: all)
  --components {all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} [{all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} ...]
                                                  Component datasets to download (comma-separated)
                                                  (default: all)
  --dest DEST                                     Where to put the uncompressed data (default:
                                                  uncompressed/)
  --dest_compressed DEST_COMPRESSED               Where to download the compressed data (default:
                                                  compressed/)
  --keep_compressed KEEP_COMPRESSED               Don&#39;t delete compressed files after decompression
                                                  (default: False)
  --only_download ONLY_DOWNLOAD                   Only download compressed data (default: False)
  --max_tries_per_model MAX_TRIES_PER_MODEL       Number of times to try to download model if
                                                  checksum fails. (default: 3)
  --connections_total CONNECTIONS_TOTAL           Number of simultaneous aria2c connections overall
                                                  (note: if not using the RPC server, this is per-
                                                  worker) (default: 8)
  --connections_per_server_per_download CONNECTIONS_PER_SERVER_PER_DOWNLOAD
                                                  Number of simulatneous aria2c connections per
                                                  server per download. Defaults to
                                                  &#39;total_connections&#39; (note: if not using the RPC
                                                  server, this is per-worker)
  --n_workers N_WORKERS                           Number of workers to use (default: 32)
  --num_chunk NUM_CHUNK                           Download the kth slice of the overall dataset
                                                  (default: 0)
  --num_total_chunks NUM_TOTAL_CHUNKS             Download the dataset in N total chunks. Use with &#39;
                                                  --num_chunk&#39; (default: 1)
  --ignore_checksum IGNORE_CHECKSUM               Ignore checksum validation (default: False)
  --dryrun                                        Keep compressed files even after decompressing
                                                  (default: False)
  --aria2_uri ARIA2_URI                           Location of aria2c RPC (if None, use CLI)
                                                  (default: http://localhost:6800)
  --aria2_cmdline_opts ARIA2_CMDLINE_OPTS         Opts to pass to aria2c (default: )
  --aria2_create_server ARIA2_CREATE_SERVER       Create a RPC server at aria2_uri (default: True)
  --aria2_secret ARIA2_SECRET                     Secret for aria2c RPC (default: )
  --agree_all                                     Agree to all license clickwraps. (default: False)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

