{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "from omnidata_tools.dataset.download import download\n",
    "from fastcore.script import anno_parser\n",
    "import os\n",
    "os.environ[\"COLUMNS\"] = '100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Dataset\n",
    "\n",
    "To find statistics about the starter dataset, please see the starter dataset repo [here](https://github.com/EPFL-VILAB/omnidata-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download/Installation\n",
    "\n",
    "**`omnitools.download` is a one-line utility for downloading the starter (and other similar) datasets.**\n",
    "\n",
    "\n",
    "The download tool is designed to be fast and easy to use (it's built off of [aria2](https://aria2.github.io/)). We regularly get 70MB/s downloading from the EPFL servers to Berkeley. It's written pretty generally, too, so the tool can also be used to download other datasets stored in a similar format (i.e. other datasets formatted similarly to annotator outputs, like [Taskonomy](//taskonomy.stanford.edu)).\n",
    "<br>**_Note:_** There's also an inverse **`omnitools.upload`** for uploading an annotator-generated dataset to a server.\n",
    "<!-- **_NOTE:_  There's also a complementary `omnitools.upload` that compresses and stores datasets in a compliant format. If you use the omnidata annotator to create a new datset, then `omnitools.upload` might be useful for when you want to distribute that dataset. I.e. other people will be able to use the download tool to download your dataset.** -->\n",
    "\n",
    "To download the starter dataset, make sure that omnidata-tooling is installed (`pip install omnidata-tools`) and then run the full download command which will prompt you to accept the component licenses and then proceed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Install a the 'debug' subsets of the Replica and Taskonomy components of the dataset\n",
    "omnitools.download rgb normals point_info \\\n",
    "  --components replica taskonomy \\\n",
    "  --subset debug \\\n",
    "  --dest ./omnidata_starter_dataset/ \\\n",
    "  --connections_total 30 --agree\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![./assets/download_example.jpg](https://alexsax.github.io/omnidata-tools/images/download_example.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command-line options\n",
    "\n",
    "`omnitools.download` is pretty configurable, and you can choose which comonents/subset/split/tasks to download and extract. The downloader will spawn many workers to then download those compressed files, verify the download against checksums on the server, and unpack them. Here are the available options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--subset {debug,tiny,medium,full,fullplus}]\n",
      "                             [--split {train,val,test,all}]\n",
      "                             [--components {all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} [{all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} ...]]\n",
      "                             [--dest DEST] [--dest_compressed DEST_COMPRESSED]\n",
      "                             [--keep_compressed KEEP_COMPRESSED] [--only_download ONLY_DOWNLOAD]\n",
      "                             [--max_tries_per_model MAX_TRIES_PER_MODEL]\n",
      "                             [--connections_total CONNECTIONS_TOTAL]\n",
      "                             [--connections_per_server_per_download CONNECTIONS_PER_SERVER_PER_DOWNLOAD]\n",
      "                             [--n_workers N_WORKERS] [--num_chunk NUM_CHUNK]\n",
      "                             [--num_total_chunks NUM_TOTAL_CHUNKS]\n",
      "                             [--ignore_checksum IGNORE_CHECKSUM] [--dryrun] [--aria2_uri ARIA2_URI]\n",
      "                             [--aria2_cmdline_opts ARIA2_CMDLINE_OPTS]\n",
      "                             [--aria2_create_server ARIA2_CREATE_SERVER]\n",
      "                             [--aria2_secret ARIA2_SECRET] [--agree_all]\n",
      "                             domains [domains ...]\n",
      "\n",
      "Downloads Omnidata starter dataset. --- The data is stored on the remote server in a compressed\n",
      "format (.tar.gz). This function downloads the compressed and decompresses it. Examples: python\n",
      "download_tools.py rgb normals point_info --components clevr_simple clevr_complex --connections_total\n",
      "30\n",
      "\n",
      "positional arguments:\n",
      "  domains                                         Domains to download (comma-separated or 'all')\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help                                      show this help message and exit\n",
      "  --subset {debug,tiny,medium,full,fullplus}      Subset to download (default: debug)\n",
      "  --split {train,val,test,all}                    Split to download (default: all)\n",
      "  --components {all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} [{all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} ...]\n",
      "                                                  Component datasets to download (comma-separated)\n",
      "                                                  (default: all)\n",
      "  --dest DEST                                     Where to put the uncompressed data (default:\n",
      "                                                  uncompressed/)\n",
      "  --dest_compressed DEST_COMPRESSED               Where to download the compressed data (default:\n",
      "                                                  compressed/)\n",
      "  --keep_compressed KEEP_COMPRESSED               Don't delete compressed files after decompression\n",
      "                                                  (default: False)\n",
      "  --only_download ONLY_DOWNLOAD                   Only download compressed data (default: False)\n",
      "  --max_tries_per_model MAX_TRIES_PER_MODEL       Number of times to try to download model if\n",
      "                                                  checksum fails. (default: 3)\n",
      "  --connections_total CONNECTIONS_TOTAL           Number of simultaneous aria2c connections overall\n",
      "                                                  (note: if not using the RPC server, this is per-\n",
      "                                                  worker) (default: 8)\n",
      "  --connections_per_server_per_download CONNECTIONS_PER_SERVER_PER_DOWNLOAD\n",
      "                                                  Number of simulatneous aria2c connections per\n",
      "                                                  server per download. Defaults to\n",
      "                                                  'total_connections' (note: if not using the RPC\n",
      "                                                  server, this is per-worker)\n",
      "  --n_workers N_WORKERS                           Number of workers to use (default: 32)\n",
      "  --num_chunk NUM_CHUNK                           Download the kth slice of the overall dataset\n",
      "                                                  (default: 0)\n",
      "  --num_total_chunks NUM_TOTAL_CHUNKS             Download the dataset in N total chunks. Use with '\n",
      "                                                  --num_chunk' (default: 1)\n",
      "  --ignore_checksum IGNORE_CHECKSUM               Ignore checksum validation (default: False)\n",
      "  --dryrun                                        Keep compressed files even after decompressing\n",
      "                                                  (default: False)\n",
      "  --aria2_uri ARIA2_URI                           Location of aria2c RPC (if None, use CLI)\n",
      "                                                  (default: http://localhost:6800)\n",
      "  --aria2_cmdline_opts ARIA2_CMDLINE_OPTS         Opts to pass to aria2c (default: )\n",
      "  --aria2_create_server ARIA2_CREATE_SERVER       Create a RPC server at aria2_uri (default: True)\n",
      "  --aria2_secret ARIA2_SECRET                     Secret for aria2c RPC (default: )\n",
      "  --agree_all                                     Agree to all license clickwraps. (default: False)\n"
     ]
    }
   ],
   "source": [
    "# Usage: should be omnitools.download :)\n",
    "anno_parser(download).print_help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
