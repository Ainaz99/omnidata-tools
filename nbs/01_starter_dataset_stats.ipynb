{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Dataset Overview \n",
    "\n",
    "[Just a list of the settings/settings per component]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/alexsax/omnidata-tools/raw/main/docs/images/starter_dataset.png\" alt=\"Starter dataset components and domains\" style='max-width: 100%;'/>\n",
    "\n",
    "## Introduction:\n",
    "We provide a Starter Dataset generated by Omnidata Pipeline from some existing 3D datasets. It contains more than `14 million` images from over `2000 spaces` with `21 different mid-level vision cues` per image. The dataset covers very diverse scenes (indoors and outdoors) and views (scene- and object-centric).\n",
    "\n",
    "\n",
    "## Sample Data:\n",
    "We provide a sample data from a random building in our **GSO + Replica** dataset split, which is created by scattering [Google Scanned Objects](https://app.ignitionrobotics.org/GoogleResearch/fuel/collections/Google%20Scanned%20Objects) around [Replica](https://github.com/facebookresearch/Replica-Dataset) buildings using the [Habitat](https://github.com/facebookresearch/habitat-sim) environment. This is only a sample scene (with mostly object-centric views) from over `2000 scenes` available in the full dataset.\n",
    "\n",
    "You can download and untar the sample data with the following command:\n",
    "\n",
    "```bash\n",
    "wget https://drive.switch.ch/index.php/s/MkygxW0WLiLKsNz/download\n",
    "tar -xf download\n",
    "```\n",
    "\n",
    "Now the sample dataset is available in the folder `omnidata_sample_dataset`.\n",
    "\n",
    "| [Sample Data (GSO+Replica)](https://github.com/Ainaz99/omnidata-sample-data) | \n",
    "| :-------------: |\n",
    "| ![](./assets/mesh1.png) \n",
    "\n",
    "\n",
    "\n",
    "## Data Statistics\n",
    "| ![](./assets/statistics/train_test_val) | Taskonomy | Replica | GSO+Replica | HM3D |\n",
    "| :-------------: |:-------------:|:-------------:|:-------------:|:-------------:| \n",
    "| Field of View | <img src=\"/omnidata-tools/images/statistics/field_of_view/taskonomy_field_of_view.png\" alt=\"Starter dataset components and domains\" style='max-width: 100%;'/> | ![](https://github.com/alexsax/omnidata-tools/raw/main/docs/images/statistics/field_of_view/replica_field_of_view.png) | ![](https://github.com/alexsax/omnidata-tools/raw/main/docs/images/statistics/field_of_view/gso_field_of_view.png) | ![](https://github.com/alexsax/omnidata-tools/raw/main/docs/images/statistics/field_of_view/hm3d_field_of_view.png)  |\n",
    "| Camera Pitch |![](./assets/statistics/camera_pitch/taskonomy_camera_pitch.png) | ![](./assets/statistics/camera_pitch/replica_camera_pitch.png) | ![](./assets/statistics/camera_pitch/gso_camera_pitch.png) | ![](./assets/statistics/camera_pitch/hm3d_camera_pitch.png)  |\n",
    "| Camera Roll | ![](./assets/statistics/camera_roll/taskonomy_camera_roll.png) | ![](./assets/statistics/camera_roll/replica_camera_roll.png) | ![](./assets/statistics/camera_roll/gso_camera_roll.png) | ![](./assets/statistics/camera_roll/hm3d_camera_roll.png)  | \n",
    "| Obliqueness Angle | ![](./assets/statistics/obliqueness_angle/taskonomy_obliqueness_angle.png) | ![](./assets/statistics/obliqueness_angle/replica_obliqueness_angle.png) | ![](./assets/statistics/obliqueness_angle/gso_obliqueness_angle.png) | ![](./assets/statistics/obliqueness_angle/hm3d_obliqueness_angle.png)  |\n",
    "| Camera Distance | ![](./assets/statistics/camera_distance/taskonomy_camera_distance.png) | ![](./assets/statistics/camera_distance/replica_camera_distance.png) | ![](./assets/statistics/camera_distance/gso_camera_distance.png) | ![](./assets/statistics/camera_distance/hm3d_camera_distance.png)  |\n",
    "| Views per Point | ![](./assets/statistics/views_per_point/taskonomy_views_per_point.png) | ![](./assets/statistics/views_per_point/replica_views_per_point.png) | ![](./assets/statistics/views_per_point/gso_views_per_point.png) | ![](./assets/statistics/views_per_point/hm3d_views_per_point.png)  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Citation\n",
    "If you find this dataset useful in your research, please cite our paper:\n",
    "```\n",
    "@inproceedings{eftekhar2021omnidata,\n",
    "  title={Omnidata: A Scalable Pipeline for Making Multi-Task Mid-Level Vision Datasets From 3D Scans},\n",
    "  author={Eftekhar, Ainaz and Sax, Alexander and Malik, Jitendra and Zamir, Amir},\n",
    "  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n",
    "  pages={10786--10796},\n",
    "  year={2021}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
